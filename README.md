# Clash Royale Facial Emoji Recognition

Este projeto utiliza **Mediapipe**, **OpenCV** e **scikit-learn** para detectar expressÃµes faciais atravÃ©s da webcam e exibir emotes do jogo Clash Royale conforme a emoÃ§Ã£o identificada.

---

## Funcionalidade

1. **Coleta de dados**: Captura imagens da webcam para diferentes expressÃµes faciais
2. **Treinamento do modelo**: Cria um classificador de machine learning com os dados coletados
3. **Reconhecimento em tempo real**: Detecta expressÃµes faciais e exibe emotes correspondentes

---

## Requisitos

- Python 3.10
- Windows / macOS / Linux
- Webcam funcionando

### Bibliotecas necessÃ¡rias:
```bash
mediapipe
opencv-python
scikit-learn
joblib
numpy
pillow
playsound
```

---

## âš™ï¸ Configurando o ambiente

1. **Abra o terminal** no diretÃ³rio do projeto

2. **Crie o ambiente virtual**:
```powershell
py -3.10 -m venv venv
```

3. **Ative o ambiente virtual**:
```powershell
venv\Scripts\Activate.ps1
```

4. **Permita a execuÃ§Ã£o de scripts PowerShell** (apenas na primeira vez):
```powershell
Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned
```

5. **Instale as dependÃªncias**:
```powershell
pip install mediapipe opencv-python scikit-learn joblib numpy pillow playsound
```

---

## Executando o Projeto (Fluxo Completo)

### Passo 1: Coleta de Dados

Execute o script para coletar imagens de treinamento:

```powershell
python collectData.py
```

**Como funciona:**
- A webcam serÃ¡ aberta mostrando a tela "Collect"
- Para cada expressÃ£o (crying, thumbsUp, angry, laughing, neutral), pressione **ENTER** para iniciar a coleta
- O script capturarÃ¡ automaticamente **300 amostras** por expressÃ£o
- Pontos faciais serÃ£o mostrados em tempo real na tela
- As features faciais serÃ£o salvas como arquivos `.npy` na pasta `data/`
- Pressione **ESC** para sair a qualquer momento

### Passo 2: Treinamento do Modelo

ApÃ³s coletar os dados, treine o classificador:

```powershell
python trainModel.py
```

**O que acontece:**
- Carrega todos os dados `.npy` da pasta `data/`
- Extrai caracterÃ­sticas faciais normalizadas
- Treina um modelo **SVM com kernel RBF** (Support Vector Machine)
- Divide os dados em treino (85%) e teste (15%)
- Mostra o **relatÃ³rio de classificaÃ§Ã£o** com mÃ©tricas de acurÃ¡cia
- Salva o modelo treinado como `models/face_expr_model.joblib`

### ğŸ® Passo 3: Reconhecimento em Tempo Real

Com o modelo treinado, execute o reconhecimento:

```powershell
python realtime.py
```

**Funcionalidades:**
- Detecta rostos em tempo real pela webcam
- Classifica a expressÃ£o facial usando o modelo treinado
- Exibe o **emote visual** do Clash Royale no canto inferior direito
- Toca o **som correspondente** Ã  expressÃ£o detectada
- Mostra a **label e confianÃ§a** da prediÃ§Ã£o no topo da tela
- **Threshold de confianÃ§a**: 10% (ajustÃ¡vel via `THRESHOLD`)
- **Delay entre sons**: 2 segundos (evita repetiÃ§Ã£o excessiva)

---

## Estrutura do Projeto

```
clash-royale/
â”‚
â”œâ”€â”€ collectData.py          # Coleta features faciais para treinamento
â”œâ”€â”€ trainModel.py           # Treina o modelo de classificaÃ§Ã£o
â”œâ”€â”€ realtime.py             # Reconhecimento em tempo real + emotes
â”œâ”€â”€ utils.py                # FunÃ§Ãµes auxiliares (extraÃ§Ã£o de features)
â”œâ”€â”€ models/                 # Pasta para modelos treinados
â”‚   â””â”€â”€ face_expr_model.joblib  # Modelo salvo (gerado apÃ³s treinamento)
â”œâ”€â”€ data/                   # Pasta com os dados coletados
â”‚   â”œâ”€â”€ thumbsUp/           # Features para joinha
â”‚   â”œâ”€â”€ laughing/           # Features para risada
â”‚   â”œâ”€â”€ crying/             # Features para choro
â”‚   â”œâ”€â”€ angry/              # Features para raiva
â”‚   â””â”€â”€ neutral/            # Features para neutro
â”œâ”€â”€ emotes/                 # Imagens PNG dos emotes do Clash Royale
â”‚   â”œâ”€â”€ thumbsUp.png
â”‚   â”œâ”€â”€ laughing.png
â”‚   â”œâ”€â”€ crying.png
â”‚   â””â”€â”€ angry.mp3
â”œâ”€â”€ sounds/                 # Sons MP3 dos emotes do Clash Royale
â”‚   â”œâ”€â”€ thumbsUp.mp3
â”‚   â”œâ”€â”€ laughing.mp3
â”‚   â”œâ”€â”€ crying.mp3
â”‚   â””â”€â”€ angry.mp3
â”œâ”€â”€ venv/                   # Ambiente virtual
â””â”€â”€ README.md
```

---

## Treinamento Personalizado

Se quiser melhorar o modelo:

1. **Colete mais dados** com `collectData.py`
2. **Ajuste parÃ¢metros** em `trainModel.py`:
```python
# Exemplo de ajuste de parÃ¢metros do SVM
clf = SVC(
    kernel="rbf", 
    probability=True, 
    class_weight="balanced", 
    random_state=42,
    C=1.0,           # ParÃ¢metro de regularizaÃ§Ã£o
    gamma='scale'     # Coeficiente do kernel
)
```

3. **Execute novamente** o fluxo completo:
```powershell
python collectData.py
python trainModel.py
python realtime.py
```

---

## Dicas para Melhor Desempenho

- **IluminaÃ§Ã£o**: Mantenha o rosto bem iluminado e uniforme
- **PosiÃ§Ã£o**: Fique centralizado na cÃ¢mera a ~50cm de distÃ¢ncia
- **ExpressÃµes**: FaÃ§a expressÃµes exageradas durante a coleta de dados
- **ConsistÃªncia**: Mantenha a mesma expressÃ£o durante toda a coleta de cada label
- **Background**: Use fundo neutro para melhor detecÃ§Ã£o

---

## SoluÃ§Ã£o de Problemas

**Problema**: Webcam nÃ£o abre  
**SoluÃ§Ã£o**: Verifique se outra aplicaÃ§Ã£o nÃ£o estÃ¡ usando a cÃ¢mera

**Problema**: Erro "ModuleNotFoundError"  
**SoluÃ§Ã£o**: Ative o ambiente virtual e reinstale as dependÃªncias

**Problema**: Baixa acurÃ¡cia nas prediÃ§Ãµes  
**SoluÃ§Ã£o**: 
- Colete mais dados de treinamento (aumente `SAMPLES_PER_LABEL`)
- Verifique a iluminaÃ§Ã£o e posiÃ§Ã£o do rosto
- Ajuste o `THRESHOLD` no `realtime.py`

**Problema**: Sons nÃ£o tocam  
**SoluÃ§Ã£o**: Verifique se os arquivos MP3 estÃ£o na pasta `sounds/` com nomes corretos

**Problema**: Emotes nÃ£o aparecem  
**SoluÃ§Ã£o**: Verifique se as imagens PNG estÃ£o na pasta `emotes/` com nomes corretos

*Nota: Execute os scripts na ordem indicada para garantir o funcionamento correto do sistema.*

---
